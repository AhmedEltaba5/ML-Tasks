{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Sentence Transformers: Multilingual Sentence, Paragraph, and Image Embeddings using BERT & Co.](https://github.com/UKPLab/sentence-transformers)\n",
    "\n",
    "This framework provides an easy method to compute dense vector representations for sentences, paragraphs, and images. The models are based on transformer networks like BERT / RoBERTa / XLM-RoBERTa etc. and achieve state-of-the-art performance in various task. Text is embedding in vector space such that similar text is close and can efficiently be found using cosine similarity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library provide an increasing number of [state-of-the-art pretrained models](https://www.sbert.net/docs/pretrained_models.html) for more than 100 languages, fine-tuned for various use-cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "```bash\n",
    "pip install -U sentence-transformers\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First download a pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-13T23:19:37.424316Z",
     "start_time": "2021-11-13T23:19:36.918845Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then provide some sentences to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-13T23:23:42.546272Z",
     "start_time": "2021-11-13T23:23:42.511613Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences = [\"The company HuggingFace is based in New York City\",\n",
    "    \"Apples are especially bad for your health\", \n",
    "    \"HuggingFace's headquarters are situated in Manhattan\"]\n",
    "\n",
    "sentence_embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it already. We now have a list of numpy arrays with the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-13T23:23:52.623299Z",
     "start_time": "2021-11-13T23:23:52.585527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_554bd_row0_col0,#T_554bd_row1_col1,#T_554bd_row2_col2{\n",
       "            background-color:  #0000ff;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_554bd_row0_col1{\n",
       "            background-color:  #eeeef3;\n",
       "            color:  #000000;\n",
       "        }#T_554bd_row0_col2{\n",
       "            background-color:  #2626fd;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_554bd_row1_col0,#T_554bd_row1_col2,#T_554bd_row2_col1{\n",
       "            background-color:  #f0f0f3;\n",
       "            color:  #000000;\n",
       "        }#T_554bd_row2_col0{\n",
       "            background-color:  #2727fd;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_554bd_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >s_0</th>        <th class=\"col_heading level0 col1\" >s_1</th>        <th class=\"col_heading level0 col2\" >s_2</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_554bd_level0_row0\" class=\"row_heading level0 row0\" >The company HuggingFace is based in New York City</th>\n",
       "                        <td id=\"T_554bd_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "                        <td id=\"T_554bd_row0_col1\" class=\"data row0 col1\" >0.027979</td>\n",
       "                        <td id=\"T_554bd_row0_col2\" class=\"data row0 col2\" >0.843274</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_554bd_level0_row1\" class=\"row_heading level0 row1\" >Apples are especially bad for your health</th>\n",
       "                        <td id=\"T_554bd_row1_col0\" class=\"data row1 col0\" >0.027979</td>\n",
       "                        <td id=\"T_554bd_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "                        <td id=\"T_554bd_row1_col2\" class=\"data row1 col2\" >0.013139</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_554bd_level0_row2\" class=\"row_heading level0 row2\" >HuggingFace's headquarters are situated in Manhattan</th>\n",
       "                        <td id=\"T_554bd_row2_col0\" class=\"data row2 col0\" >0.843274</td>\n",
       "                        <td id=\"T_554bd_row2_col1\" class=\"data row2 col1\" >0.013139</td>\n",
       "                        <td id=\"T_554bd_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f462d177a50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities = cosine_similarity(sentence_embeddings, sentence_embeddings)\n",
    "\n",
    "pd.DataFrame(similarities, columns=[f's_{i}' for i in range(len(sentences))],\n",
    "             index=sentences).style.background_gradient(cmap=cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, This framework allows you to fine-tune your own sentence embedding methods, so that you get task-specific sentence embeddings. You have various options to choose from in order to get perfect sentence embeddings for your specific task.\n",
    "\n",
    "See [Training Overview](https://www.sbert.net/docs/training/overview.html) for an introduction how to train your own embedding models. We provide [various examples](https://github.com/UKPLab/sentence-transformers/tree/master/examples/training) how to train models on various datasets.\n",
    "\n",
    "Some highlights are:\n",
    "\n",
    "- Support of various transformer networks including BERT, RoBERTa, XLM-R, DistilBERT, Electra, BART, ...\n",
    "- Multi-Lingual and multi-task learning\n",
    "- Evaluation during training to find optimal model\n",
    "- [10+ loss-functions](https://www.sbert.net/docs/package_reference/losses.html) allowing to tune models specifically for semantic search, paraphrase mining, semantic similarity comparison, clustering, triplet loss, contrastive loss."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
